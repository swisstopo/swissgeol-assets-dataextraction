{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is used to create input pages for the classification pipeline and create ground truth for single pages.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Place the original reports (PDFs) in `data/input/`  \n",
    "   - The folder should contain PDF files from which pages will be extracted.\n",
    "\n",
    "Specify the following parameters:  \n",
    "   - filename: Name of the PDF file to extract pages from.  \n",
    "   - wanted_page`: The page number to extract.  \n",
    "   - out_dir`: The target directory where the extracted page will be stored.\n",
    "\n",
    "Set out_dir to one of the following categories:  \n",
    "   - \"boreprofile\"  \n",
    "   - \"maps\" \n",
    "   - \"text\" \n",
    "   - \"title_page\" \n",
    "   -\"unknown\"  \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pymupdf\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "repo_root = Path.cwd().parent.resolve()\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from src.classify_scanned_page import classify_pdf\n",
    "from main import read_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"2155.pdf\"\n",
    "wanted_pages = range(0,2)\n",
    "out_category = \"\"\n",
    "\n",
    "pdf_path = os.path.join(repo_root, \"data/input/\", filename)\n",
    "out_dir = os.path.join(repo_root, f\"data/input/single_pages/{out_category}\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with pymupdf.open(pdf_path) as doc:\n",
    "   for page_index,page in enumerate(doc):\n",
    "         page_number = page_index +1\n",
    "      \n",
    "         if page_number in wanted_pages:\n",
    "               out_path= os.path.join(out_dir,f\"{ os.path.splitext(filename)[0]}_{page_number}.pdf\")\n",
    "\n",
    "               new_doc = pymupdf.open()\n",
    "\n",
    "               new_doc.insert_pdf(doc, from_page=page_index, to_page=page_index)\n",
    "               new_doc.save(out_path)\n",
    "               new_doc.close()\n",
    "               print(f\"saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = repo_root / \"data/input/reports_no_gt\"\n",
    "output_base_dir = repo_root / \"data/input/single_pages\"\n",
    "matching_params = read_params(repo_root / \"matching_params.yml\")\n",
    "\n",
    "# Max number of pages per class per report to save\n",
    "max_per_class = {\n",
    "    \"text\": 1,\n",
    "    \"boreprofile\": 2,\n",
    "    \"maps\": 2,\n",
    "    \"title_page\": 2,\n",
    "    \"unknown\": 1\n",
    "}\n",
    "\n",
    "# Get list of downloaded PDFs\n",
    "pdf_files = list(input_dir.glob(\"*.pdf\"))\n",
    "sampled_pdfs = random.sample(pdf_files, 1)\n",
    "\n",
    "# Process each PDF\n",
    "for pdf_path in tqdm(sampled_pdfs, desc=\"Classifying and saving selected pages\"):\n",
    "    classification_result = classify_pdf(pdf_path, matching_params)\n",
    "    if not classification_result:\n",
    "        continue\n",
    "\n",
    "    filename_base = pdf_path.stem\n",
    "    page_by_class = {}\n",
    "\n",
    "    # Group pages by class\n",
    "    for page_info in classification_result[\"classification\"]:\n",
    "        page_num = page_info[\"Page\"]\n",
    "        page_class = next((cls for cls, val in page_info.items() if cls != \"Page\" and val == 1), \"unknown\").lower()\n",
    "\n",
    "        page_by_class.setdefault(page_class, []).append(page_num)\n",
    "\n",
    "    # Save pages\n",
    "    with pymupdf.open(pdf_path) as doc:\n",
    "        for class_label, page_nums in page_by_class.items():\n",
    "            max_pages = max_per_class.get(class_label, 1)\n",
    "            selected_pages = random.sample(page_nums, min(len(page_nums), max_pages))\n",
    "\n",
    "            output_dir = output_base_dir / class_label\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for page_num in selected_pages:\n",
    "                out_filename = f\"{filename_base}_{page_num}.pdf\"\n",
    "                out_path = output_dir / out_filename\n",
    "\n",
    "                new_doc = pymupdf.open()\n",
    "                new_doc.insert_pdf(doc, from_page=page_num - 1, to_page=page_num - 1)\n",
    "                new_doc.save(out_path)\n",
    "                new_doc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create groundtruth based on input in subfolder of single pages:\n",
    "\n",
    "input_folder = repo_root/ \"data/input/single_pages\"\n",
    "\n",
    "# All possible classes (must match ground truth schema)\n",
    "classes = [\"Text\", \"Boreprofile\", \"Maps\", \"Title_Page\", \"Unknown\"]\n",
    "\n",
    "folder_to_class = {\n",
    "    \"text\": \"Text\",\n",
    "    \"boreprofile\": \"Boreprofile\",\n",
    "    \"maps\": \"Maps\",\n",
    "    \"title_page\": \"Title_Page\",\n",
    "    \"unknown\": \"Unknown\"\n",
    "}\n",
    "\n",
    "ground_truth = []\n",
    "\n",
    "for class_folder in input_folder.iterdir():\n",
    "    if not class_folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    folder_name = class_folder.name.lower()\n",
    "    if folder_name not in folder_to_class:\n",
    "        print(f\"Skipping unrecognized folder: {class_folder.name}\")\n",
    "        continue\n",
    "\n",
    "    class_label = folder_to_class[folder_name]\n",
    "\n",
    "    for pdf_file in class_folder.glob(\"*.pdf\"):\n",
    "        entry = {\n",
    "            \"filename\": pdf_file.name,\n",
    "            \"classification\": [{\n",
    "                \"Page\": 1,\n",
    "                **{cls: int(cls == class_label) for cls in classes}\n",
    "            }]\n",
    "        }\n",
    "        ground_truth.append(entry)\n",
    "\n",
    "output_path = repo_root /\"data/gt_single_pages_new.json\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with output_path.open(\"w\") as f:\n",
    "    json.dump(ground_truth, f, indent=4)\n",
    "\n",
    "print(f\"Saved {len(ground_truth)} entries to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
