{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pymupdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import regex\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(os.path.join(repo_root, \"src\"))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from text import extract_words, create_text_lines, create_text_blocks\n",
    "from utils import TextWord\n",
    "from keyword_finding import find_keywords_in_lines\n",
    "from title_page import title_page_type\n",
    "from utils import closest_word_distances, y0_word_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"maps\"\n",
    "filename =\"8627_3.pdf\"\n",
    "\n",
    "pdf_path = os.path.join(repo_root, \"data/input\", input_folder)\n",
    "out_dir = os.path.join(repo_root, \"data/test\", os.path.splitext(filename)[0])\n",
    "\n",
    "#pdf_path = \"/home/lillemor/PycharmProjects/swissgeol-boreholes-dataextraction/data/geoquat/validation/\"\n",
    "\n",
    "ground_truth_path = os.path.join(repo_root,\"data/ground_truth_maps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_boreprofile = [\"bohrung\", \"bohrprofil\", \"sondage\"]\n",
    "\n",
    "pattern_maps = [\n",
    "    regex.compile(r\"1\\s*:\\s*[125](25|5)?000+\"),\n",
    "    regex.compile(r\"1\\s*:\\s*[125]((0{1,2})?([',]000)+)\")\n",
    "]\n",
    "\n",
    "def find_maps_pattern(words: list[TextWord]) -> regex.Match | None:\n",
    "    return next((match \n",
    "                 for pattern in pattern_maps \n",
    "                 for word in words \n",
    "                 if (match := pattern.search(word.text))), None)\n",
    "\n",
    "\n",
    "def classify_on_keywords(lines: list[str], words: list[TextWord]) -> str | None:\n",
    "\n",
    "    if find_keywords_in_lines(lines, keywords_boreprofile):\n",
    "        return \"boreprofile\"\n",
    "    if find_maps_pattern(words):\n",
    "        return \"map\"  \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classification Summary:\n",
      "+-------------+---------+--------------+\n",
      "|             |   Count |   Percentage |\n",
      "+=============+=========+==============+\n",
      "| Text        |       0 |         0    |\n",
      "+-------------+---------+--------------+\n",
      "| Title Page  |       0 |         0    |\n",
      "+-------------+---------+--------------+\n",
      "| Boreprofile |       3 |        13.04 |\n",
      "+-------------+---------+--------------+\n",
      "| Map         |      20 |        86.96 |\n",
      "+-------------+---------+--------------+\n",
      "| Unknown     |       0 |         0    |\n",
      "+-------------+---------+--------------+\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Boreprofile       0.00      0.00      0.00         0\n",
      "         Map       1.00      0.87      0.93        23\n",
      "\n",
      "    accuracy                           0.87        23\n",
      "   macro avg       0.50      0.43      0.47        23\n",
      "weighted avg       1.00      0.87      0.93        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification tracking\n",
    "classification_counts = {\n",
    "    \"Text\": 0,\n",
    "    \"Title Page\": 0,\n",
    "    \"Boreprofile\": 0,\n",
    "    \"Map\": 0,\n",
    "    \"Unknown\": 0\n",
    "}\n",
    "total_pages = 0\n",
    "classification_data = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(pdf_path):\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_path, filename)\n",
    "\n",
    "        with pymupdf.Document(file_path) as doc:\n",
    "            for page_index, page in enumerate(doc):\n",
    "                total_pages += 1\n",
    "                page_number = page_index + 1\n",
    "                text = page.get_text()\n",
    "\n",
    "                words = extract_words(page, page_number)\n",
    "                if not words:\n",
    "                    classification_counts[\"Unknown\"] += 1\n",
    "                    classification_data.append({\n",
    "                        \"Filename\": filename,\n",
    "                        \"Page Number\": page_number,\n",
    "                        \"Classification\": \"Unknown\"\n",
    "                    })\n",
    "                    continue\n",
    "\n",
    "                # Compute word distances and line attributes\n",
    "                distances = closest_word_distances(words)\n",
    "                median_distance = np.median(distances) if distances else None\n",
    "                lines = create_text_lines(page, page_number)\n",
    "                words_per_line = [len(line.words) for line in lines]\n",
    "                mean_words_per_line = np.mean(words_per_line) if words_per_line else 0\n",
    "\n",
    "                # Compute text block attributes\n",
    "                text_blocks = create_text_blocks(lines)\n",
    "                block_area = sum(block.rect.get_area() for block in text_blocks)\n",
    "                word_area = sum(word.rect.get_area()\n",
    "                                for block in text_blocks\n",
    "                                for line in block.lines\n",
    "                                for word in line.words if len(line.words) > 1)\n",
    "\n",
    "                classification = \"Unknown\"\n",
    "\n",
    "                # Rule-based classification\n",
    "                if block_area > 0 and word_area / block_area > 1 and mean_words_per_line > 3:\n",
    "                    classification = \"Title Page\" if title_page_type(text) else \"Text\"\n",
    "                else:\n",
    "                    classify_keywords = classify_on_keywords(lines, words)\n",
    "                    if classify_keywords in classification_counts:\n",
    "                        classification = classify_keywords\n",
    "                    else:\n",
    "                        clusters = y0_word_cluster(lines)\n",
    "                        filtered_clusters = [cluster for cluster in clusters if len(cluster) > 1]\n",
    "                        longest_cluster = max(map(len, filtered_clusters), default=0)\n",
    "\n",
    "                        if median_distance is not None and median_distance < 20 and longest_cluster > 4:\n",
    "                            classification = \"Boreprofile\"\n",
    "                        else:\n",
    "                            classification = \"Map\"\n",
    "\n",
    "                # Update class counts\n",
    "                classification_counts[classification] += 1\n",
    "                classification_data.append({\n",
    "                    \"Filename\": filename,\n",
    "                    \"Page Number\": page_number,\n",
    "                    \"Classification\": classification\n",
    "                })\n",
    "\n",
    "df = pd.DataFrame(classification_data)\n",
    "\n",
    "# classification summary\n",
    "summary = pd.DataFrame.from_dict(classification_counts, orient='index', columns=['Count'])\n",
    "summary['Percentage'] = (summary['Count'] / total_pages * 100).round(2)\n",
    "\n",
    "logging.info(\"Classification Summary:\")\n",
    "logging.info(tabulate(summary, headers=\"keys\", tablefmt=\"grid\"))\n",
    "\n",
    "#Save results to CSV\n",
    "df.to_csv(os.path.join(repo_root,\"data/classification_results.csv\"), index=False)\n",
    "\n",
    "# TODO: implement groundtruth\n",
    "try:\n",
    "    ground_truth = pd.read_csv(ground_truth_path)\n",
    "    df = df.merge(ground_truth, on=[\"Filename\", \"Page Number\"], how=\"left\")\n",
    "    df[\"Correct\"] = df[\"Classification\"] == df[\"True Label\"]\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    report = classification_report(df[\"True Label\"], df[\"Classification\"], zero_division=0)\n",
    "    logging.info(\"\\nClassification Report:\\n\" + report)\n",
    "except FileNotFoundError:\n",
    "    logging.info(\"\\nNo ground truth available for evaluation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
