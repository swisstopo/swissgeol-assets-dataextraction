{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import fitz\n",
    "import json\n",
    "import yaml\n",
    "import regex\n",
    "import re\n",
    "\n",
    "from utils import  TextWord,create_text_lines, TextLine\n",
    "from detect_language import detect_language_of_document\n",
    "from keyword_finding import get_keywords_by_language, find_keywords_in_lines, TOC, extract_by_bookmarks\n",
    "\n",
    "base_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/NAB/Berichte_NAB 10-025_Kurzarbeitsprogram Geothermiebohrung Schlattingen.PDF\"\n",
    "output_path = \"data/predictions.json\"\n",
    "\n",
    "with open(os.path.join(base_dir, \"matching_params.yml\"), \"r\") as params_file:\n",
    "    matching_params = yaml.safe_load(params_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_keywords( text_lines: list[TextLine], found_keywords: list[dict]) : ##rmak more robust\n",
    "\n",
    "    toc_entries = []\n",
    "    toc_patterns = [\n",
    "    {\n",
    "        \"pattern\": regex.compile(\n",
    "            r\"^(\\d+(\\.\\d+)*)\\s+([\\p{L}\\p{M}\\p{N}\\p{P}\\-\\s]+)\\s*(\\.+|\\s{2,})\\s*([ivxlcdm]+|\\d+)$\",\n",
    "            flags=regex.VERBOSE | regex.IGNORECASE,\n",
    "        ),\n",
    "        \"header_group\": 3,\n",
    "        \"page_group\": 5,\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": regex.compile(\n",
    "            r\"^([\\p{L}\\p{M}\\p{N}\\p{P}\\-\\s]+)\\s*(\\.+|\\s{2,})\\s*([ivxlcdm]+|\\d+)$\",\n",
    "            flags=regex.VERBOSE | regex.IGNORECASE,\n",
    "        ),\n",
    "        \"header_group\": 1,\n",
    "        \"page_group\": 3,\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": regex.compile(\n",
    "            r\"^(\\d+(\\.\\d+)*)\\s+([\\p{L}\\p{M}\\p{N}\\p{P}\\-\\s]+)\\s+([ivxlcdm]+|\\d+)$\",\n",
    "            flags=regex.VERBOSE | regex.IGNORECASE,\n",
    "        ),\n",
    "        \"header_group\": 3,\n",
    "        \"page_group\": 4,\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": regex.compile(\n",
    "            r\"^([\\p{L}\\p{M}\\p{N}\\p{P}\\-\\s]+)\\s+([ivxlcdm]+|\\d+)$\",\n",
    "            flags=regex.VERBOSE | regex.IGNORECASE,\n",
    "        ),\n",
    "        \"header_group\": 1,\n",
    "        \"page_group\": 2,\n",
    "    },\n",
    "]\n",
    "\n",
    "    for keyword_entry in found_keywords:\n",
    "        line_index = text_lines.index(keyword_entry[\"line\"])\n",
    "        break  # only first keyword\n",
    "\n",
    "     # Process subsequent lines starting from the keyword's line\n",
    "    for line in text_lines[line_index+1:]:\n",
    "        \n",
    "        line_matched = False\n",
    "\n",
    "        for entry in toc_patterns:\n",
    "            toc_pattern = entry[\"pattern\"]\n",
    "            match = toc_pattern.match(line.line_text())\n",
    "            if match:\n",
    "                header = match.group(entry[\"header_group\"]).strip()\n",
    "                page = match.group(entry[\"page_group\"]).strip()\n",
    "                cleaned_header = clean_header(header)\n",
    "                toc_entries.append({\"header\": cleaned_header, \"page\": page})\n",
    "                line_matched = True\n",
    "                break\n",
    "\n",
    "        if not line_matched:\n",
    "            print(f\"Unmatched line: {line.line_text()}\")\n",
    "            break\n",
    "    return TOC(entries=toc_entries) if toc_entries else None\n",
    "\n",
    "def clean_header(header: str) -> str:\n",
    "    return regex.sub(r\"\\.{2,}\", \"\", header).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC(entries=[{'heading': 'NAB 10-25 Cover', 'page': 1, 'level': 1}, {'heading': 'Titelseite innen', 'page': 3, 'level': 1}, {'heading': 'Copyright', 'page': 4, 'level': 1}, {'heading': 'Inhaltsverzeichnis', 'page': 5, 'level': 1}, {'heading': 'Tabellenverzeichnis', 'page': 5, 'level': 1}, {'heading': 'Figurenverzeichnis', 'page': 6, 'level': 1}, {'heading': '1 Einleitung und Zielsetzung', 'page': 7, 'level': 1}, {'heading': '2 Geologie', 'page': 9, 'level': 1}, {'heading': '2.1 Beschreibung des Untersuchungsgebietes', 'page': 9, 'level': 2}, {'heading': '2.2 Prognose Bohrprofil', 'page': 12, 'level': 2}, {'heading': '3 Bohrarbeiten', 'page': 13, 'level': 1}, {'heading': '3.1 Bohrsp√ºlung', 'page': 15, 'level': 2}, {'heading': '4 Vorgesehene Untersuchungen', 'page': 17, 'level': 1}, {'heading': '4.1 Bohrstellen-Geologie', 'page': 17, 'level': 2}, {'heading': '4.2 Bohrloch-Geophysik', 'page': 19, 'level': 2}, {'heading': '4.3 Hydrogeologie und Hydrochemie', 'page': 22, 'level': 2}, {'heading': '4.4 Geotechnik und Felsmechanik', 'page': 25, 'level': 2}, {'heading': '5 Bohrplatz', 'page': 29, 'level': 1}, {'heading': '6 Projektorganisation', 'page': 31, 'level': 1}, {'heading': '7 Referenzen', 'page': 33, 'level': 1}])\n"
     ]
    }
   ],
   "source": [
    "with fitz.open(pdf_path) as doc:\n",
    "\n",
    "    text_lines = create_text_lines(doc) \n",
    "    language = detect_language_of_document(doc)\n",
    "    table_of_content = extract_by_bookmarks(doc)\n",
    "\n",
    "    if not table_of_content:\n",
    "        keywords = get_keywords_by_language(language, matching_params)\n",
    "    \n",
    "        found_keywords =find_keywords_in_lines(text_lines, keywords)\n",
    "        if found_keywords:\n",
    "            table_of_content =extract_by_keywords(text_lines, found_keywords) \n",
    "    \n",
    "    print(table_of_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fitz.Document(pdf_path) as doc:\n",
    "    language = detect_language_of_document(doc)\n",
    "\n",
    "    keywords = get_keywords_by_language(language, matching_params)\n",
    "    table_of_content = extract_by_bookmarks(doc)\n",
    "    found_keywords = []\n",
    "    for page_index, page in enumerate(doc):\n",
    "        page_number = page_index + 1\n",
    "        words = []\n",
    "        words_by_line = {}\n",
    "\n",
    "        for x0, y0, x1, y1, word, block_no, line_no, _word_no in page.get_text(\"words\"):\n",
    "            rect = fitz.Rect(x0, y0, x1, y1) * page.rotation_matrix\n",
    "            text_word = TextWord(rect= rect, text = word, page = page_number)\n",
    "            words.append(text_word)\n",
    "                \n",
    "    table_of_content=table_of_content.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, \"w\", encoding = \"utf-8\") as file:\n",
    "    json.dump(table_of_content, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(item, title=\"\"):\n",
    "    DPI = 150  # use this resolution\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # %matplotlib inline\n",
    "    pix = item.get_pixmap(dpi=DPI)\n",
    "    img = np.ndarray([pix.h, pix.w, 3], dtype=np.uint8, buffer=pix.samples_mv)\n",
    "    plt.figure(dpi=DPI)  # set the figure's DPI\n",
    "    plt.title(title)  # set title of image\n",
    "    _ = plt.imshow(img, extent=(0, pix.w * 72 / DPI, pix.h * 72 / DPI, 0))\n",
    "\n",
    "if not hasattr(fitz.Page, \"find_tables\"):\n",
    "    raise RuntimeError(\"This PyMuPDF version does not support the table feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fitz.Document(pdf_path) as doc:\n",
    "    page = doc[11]\n",
    "    tabs = page.find_tables()  # detect the tables\n",
    "    for i,tab in enumerate(tabs):  # iterate over all tables\n",
    "        for cell in tab.header.cells:\n",
    "            page.draw_rect(cell,color=fitz.pdfcolor[\"red\"],width=0.3)\n",
    "        page.draw_rect(tab.bbox,color=fitz.pdfcolor[\"green\"])\n",
    "        print(f\"Table {i} column names: {tab.header.names}, external: {tab.header.external}\")\n",
    "        \n",
    "    #show_image(page, f\"Table & Header BBoxes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
