{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pymupdf\n",
    "import numpy as np\n",
    "import math\n",
    "import regex\n",
    "from collections import defaultdict\n",
    "\n",
    "from text import extract_words, create_text_lines, create_text_blocks\n",
    "from utils import classify_wordpos, classify_text_density, TextWord\n",
    "from keyword_finding import find_keywords_in_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "input_folder = \"maps\"\n",
    "filename =\"8627_3.pdf\"\n",
    "\n",
    "pdf_path = os.path.join(base_dir, \"data/input\", input_folder)\n",
    "out_dir = os.path.join(base_dir, \"data/test\", os.path.splitext(filename)[0])\n",
    "\n",
    "# pdf_path = \"/home/lillemor/PycharmProjects/swissgeol-boreholes-dataextraction/data/zurich/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_distance(word1, word2):\n",
    "    \"\"\"Calculate Euclidean distance between two TextWord objects based on x0 and y0\"\"\"\n",
    "    x_dist = word1.rect.x0 - word2.rect.x0\n",
    "    y_dist = word1.rect.y0 - word2.rect.y0\n",
    "    return math.sqrt(x_dist**2 + y_dist**2)\n",
    "\n",
    "def closest_word_distances(words):\n",
    "    \"\"\"Calculate distances between each word and its closest neighbor\"\"\"\n",
    "    if not words or len(words) < 2:\n",
    "        return []\n",
    "\n",
    "    distances = []\n",
    "    for i, word in enumerate(words):\n",
    "        other_words = words[:i] + words[i+1:]  # Exclude current word\n",
    "        closest_word = min(other_words, key=lambda w: calculate_distance(word, w))\n",
    "        distances.append(calculate_distance(word, closest_word))\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_boreprofile = [\"bohrung\",\"bohrprofil\"]\n",
    "\n",
    "\n",
    "def find_maps_pattern(words:list[TextWord]):\n",
    "    pattern_maps = r\"1\\s*:\\s*[1,2,5,][0,5]*\"\n",
    "    for word in words:\n",
    "        pattern = regex.compile(pattern_maps)\n",
    "        match = pattern.search(word.text)\n",
    "        if match:\n",
    "            return match\n",
    "            \n",
    "def classify_on_keywords(lines, words):\n",
    "    keywords_on_page = find_keywords_in_lines(lines, keywords_boreprofile)\n",
    "    if keywords_on_page:\n",
    "        return \"boreprofile\"\n",
    "    if find_maps_pattern(words):\n",
    "        return \"map\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def y0_word_cluster(all_words, tolerance: int = 10):\n",
    "   \n",
    "    if not all_words:\n",
    "        return []\n",
    "\n",
    "    # Dictionary to hold clusters, keys are representative y0 values\n",
    "    grouped_y0 = defaultdict(list)\n",
    "\n",
    "    for word in all_words:\n",
    "        y0 = word.rect.y0\n",
    "        matched_y0 = None\n",
    "\n",
    "        # Check if y0 is within tolerance of an existing cluster\n",
    "        for key in grouped_y0:\n",
    "            if abs(key - y0) <= tolerance:\n",
    "                matched_y0 = key\n",
    "                break\n",
    "\n",
    "        # Add to an existing cluster or create a new one\n",
    "        if matched_y0 is not None:\n",
    "            grouped_y0[matched_y0].append(word)\n",
    "        else:\n",
    "            grouped_y0[y0].append(word)\n",
    "\n",
    "    clusters = list(grouped_y0.values())\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: (0, 0.0)\n",
      "boreprofile: (3, 0.1304)\n",
      "map: (20, 0.8696)\n",
      "unknown: (0, 0.0)\n",
      "total 23\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "text_count=0\n",
    "boreprofile_count=0\n",
    "map_count=0\n",
    "unknown_count= 0\n",
    "\n",
    "for filename in os.listdir(pdf_path):\n",
    "    # if count >=1:\n",
    "    #     break\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_path, filename)\n",
    "        \n",
    "        with pymupdf.Document(file_path) as doc: \n",
    "            for page_index,page in enumerate(doc):\n",
    "                count += 1\n",
    "\n",
    "                #page info\n",
    "                page_number = page_index +1\n",
    "                page_size = (page.rect.width, page.rect.height)\n",
    "\n",
    "                words = extract_words(page, page_number)\n",
    "                if not words:\n",
    "                    unknown_count += 1\n",
    "                    continue\n",
    "\n",
    "                #words attributes\n",
    "                word_attributes = classify_text_density(words,page_size)\n",
    "                words_position = classify_wordpos(words)\n",
    "                distances = closest_word_distances(words)\n",
    "                median_distance = np.median(distances) if distances else None\n",
    "\n",
    "                #line attributes\n",
    "                lines = create_text_lines(page, page_number)\n",
    "                words_per_line =[len(line.words) for line in lines]\n",
    "\n",
    "                #textblock attributes\n",
    "                text_blocks = create_text_blocks(lines)\n",
    "                block_area = sum([block.rect.get_area() for block in text_blocks])\n",
    "                word_area =sum([word.rect.get_area() \n",
    "                    for block in text_blocks\n",
    "                    for line in block.lines \n",
    "                    for word in line.words if len(line.words) > 1])\n",
    "                \n",
    "\n",
    "                classified = False\n",
    "                # classify based on word density within textblock and words per lines\n",
    "                if word_area/block_area > 1 and np.mean(words_per_line) >  3:\n",
    "                    text_count += 1  \n",
    "                    classified = True\n",
    " \n",
    "                else:\n",
    "                    #classify by keywords\n",
    "                    classify_keywords = classify_on_keywords(lines, words)\n",
    "                    if classify_keywords == \"boreprofile\":\n",
    "                        boreprofile_count += 1\n",
    "                        classified = True\n",
    "                    # elif classify_keywords == \"map\":\n",
    "                    #     map_count += 1\n",
    "                    #     classified = True\n",
    "\n",
    "                    #classify based on y0 alignment\n",
    "                    if not classified:\n",
    "                        ##  could also do text_blocks...\n",
    "                        clusters = y0_word_cluster(lines)\n",
    "                        ## filter out clusters with only one line\n",
    "                        filtered_clusters = [cluster for cluster in clusters if len(cluster) >=2]\n",
    "                        if filtered_clusters:           \n",
    "\n",
    "                            ### boreprofile smaller eucledian distance + longer clusters\n",
    "                            if median_distance < 20 and max((len(cluster) for cluster in filtered_clusters)) > 4:\n",
    "                                boreprofile_count +=1\n",
    "                            else:\n",
    "                                map_count+=1\n",
    "                        else:\n",
    "                            map_count +=1\n",
    "\n",
    "print(f\"text: {text_count,round(text_count/count,4)}\")\n",
    "print(f\"boreprofile: {boreprofile_count,round(boreprofile_count/count,4)}\")\n",
    "print(f\"map: {map_count,round(map_count/count,4)}\")\n",
    "print(f\"unknown: {unknown_count, round(unknown_count/count,4)}\")\n",
    "print(f\"total {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "# Construct some test data\n",
    "x, y = np.ogrid[-np.pi : np.pi : 100j, -np.pi : np.pi : 100j]\n",
    "r = np.sin(np.exp(np.sin(x) ** 3 + np.cos(y) ** 2))\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(r, 0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
